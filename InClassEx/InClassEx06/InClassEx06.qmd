---
title: "In Class Exercise 6 - Emerging Hot Spot Analysis"
author: "Kieren Chua"
date: "September 30 2024"
date-modified: "last-modified"
execute: 
    eval: true # evaulate the code first
    echo: true # See the code output
    message: false # don't see the warnings
    freeze: true # Prevent re-render
---

# Part 1 : Loading Data and Packages

```{r}
pacman::p_load(sf, sfdep, tmap, plotly, tidyverse, Kendall)
```

```{r}
hunan <- st_read(dsn="data/geospatial", layer="Hunan")
GDPPC <- read_csv("data/aspatial/Hunan_GDPPC.csv")
```

# Part 2 : Creating a Time Series Cube

We can create a time series cube by attaching
```{r}
# We cannot use fields with datetime because it is a continous field. 
# Need to convert datetime to integer 

# ! Must convert the month to integer as well using lubridate package
GDPPC_st <- spacetime(GDPPC, 
                    hunan, 
                    .loc_col = "County", # Space indicator
                    .time_col = "Year" # Time indicator
                    )
is_spacetime_cube(GDPPC_st) # Use this function to check
```

```{r}
GDPPC_nb <- GDPPC_st %>% 
            activate("geometry") %>% 
            mutate(nb = include_self(
                st_contiguity(geometry)
            ),
            wt = st_inverse_distance(nb,
                geometry,
                scale=1,
                alpha=1), # Alpha values increase distance decay
            .before=1) %>% # Go infront of table and not back
            set_nbs("nb") %>% # Dont sort, leave according to time sequence
            set_wts("wt")
```

# Part 3 : Compute G-Star

```{r}
gi_stars <- GDPPC_nb %>%
            group_by(Year) %>% # Set this to use Year
            mutate(gi_star = local_gstar_perm(
                GDPPC, nb, wt
            )) %>%
            tidyr::unnest(gi_star)
```

Now we can apply Mann-Kendall Test which tests for monotonic trends

# Part 4 : Mann-Kendall Test on Gi

```{r}
# Need at least 12 time intervals for statistical significance
cbg <- gi_stars %>% 
        ungroup() %>% # Need to ungroup the spacetime cube for plotting
        filter(County == "Changsha") |> # Alternative pipe
        select(County, Year, gi_star)
```

```{r}
p <- ggplot(data = cbg,
        aes(x = Year, y = gi_star)) +
        geom_line() + 
        theme_light()

ggplotly(p) # Make the plot interactive 
```

If the p-value is smaller than the alpha value we can reject the Null Hypothesis

if H0 : No monotonic 
if H1 : Monotonic trend present

Tau ranges from -1 to 1
-1 is a perfectly decreasing series
1 is a perfectly increasing series

## Test Report

```{r}
cbg %>% 
    summarise(mk = list(
        unclass(
            Kendall::MannKendall(gi_star)))) %>%
    tidyr::unnest_wider(mk) 
```

**sl** is the p-value, since less than 5% we can reject the null hypothesis and infer slightly increasing series

```{r}
ehsa <- gi_stars %>%
        group_by(County) %>%
        summarise(mk = list(
            unclass(
                Kendall::MannKendall(gi_star)))) %>%
        tidyr::unnest_wider(mk)
head(ehsa)
```

# Part 5 : Emerging Hot/Cold Spots Analysis

```{r}
ehsa <- emerging_hotspot_analysis( # From sfdep
    x = GDPPC_st, # Space time object
    .var = "GDPPC", # Variable of interest
    k = 1, # Number of time lags
    nsim = 99 # Number of simulations
)
```

## Visualizing EHSA classes

**Note** : Not all of them are statistically significant

```{r}
ggplot(data = ehsa,
        aes(x = classification)) +
        geom_bar()
```

```{r}
hunan_ehsa <- hunan %>%
                left_join(ehsa,
                        by = join_by(County == location))
```

```{r}
ehsa_sig <- hunan_ehsa %>% 
            filter(p_value < 0.05) # Filter p-value
tmap_mode("plot")
tm_shape(hunan_ehsa) +
    tm_polygons() +
    tm_borders(alpha = 0.5) +
tm_shape(ehsa_sig) +
    tm_fill("classification") +
    tm_borders(alpha=0.4)
```












