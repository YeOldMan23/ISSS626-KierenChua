---
title: "Hands On Exercise 4"
author: "Kieren Chua"
date: "September 14 2024"
date-modified: "last-modified"
execute: 
    eval: true # evaulate the code first
    echo: true # See the code output
    message: false # don't see the warnings
    freeze: true # Prevent re-render
---

# Part 1 : Reading the Data

Run the basic packages

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, knitr)
```

Load in the data

```{r}
hunan <- st_read(dsn = "data/geospatial/", 
                 layer = "Hunan")
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")

# Read the data to see which ones to join
colnames(hunan)
colnames(hunan2012)
```

Join on country

```{r}
hunan <- left_join(hunan,hunan2012)%>%
  select(1:4, 7, 15)

hunan
```

# Part 2 : Visualising Regional Development Indicator

Plot the GDPPC for each respective county

```{r}
#| fig-width: 12
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size=0.5)

gdppc <- qtm(hunan, "GDPPC")
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

# Part 3 : Computing Contiguity Spatial Weights

## Queen Based Contiguity Based Neighbours

```{r}
# Queen Continuity Matrix?
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

```{r}
wm_q[[1]]
```

```{r}
# Get the county name for the first index
hunan$County[1]

# Then get its neighbours
hunan$NAME_3[c(2,3,4,57,85)]

# Retrieve their GDP
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1

# View the complete weight matrix
str(wm_q)
```

## Rook Based Contiguity Based Neighbours

```{r}
wm_r <- poly2nb(hunan, queen=FALSE)
summary(wm_r)
```

## View Continguity Connections

Extract out the coordinates from the map

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

```{r}
# Verify the coords
coords <- cbind(longitude, latitude)
head(coords)
```

Plot the connections graphs

```{r}
# Queen Based
plot(hunan$geometry, border="lightgrey")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
```

```{r}
# Rook based
plot(hunan$geometry, border="lightgrey")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

Plot both of them together

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="Queen Contiguity")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
plot(hunan$geometry, border="lightgrey", main="Rook Contiguity")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

# Part 4 : Computing distance based neighbours

## Determining Cutoff Distance

```{r}
# Calculate the nearest distances
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

Since the min distance is 61.79km, round up to 62 then use as upper distance bound

## Computing adaptive distance weight matrix

```{r}
# Compute Nearest Neighbours
# 62 is the upper distance bound
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

**Quiz** : This represent the average number of links per node. In visual representaiton this represents the average number of red edges per vertex

```{r}
# Visually see split
str(wm_d62)

# Display  by name
table(hunan$County, card(wm_d62))

# Not sure that this does
n_comp <- n.comp.nb(wm_d62)
n_comp$nc
table(n_comp$comp.id)
```

Now plot by weight

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_d62, coords, add=TRUE)
plot(k1, coords, add=TRUE, col="red", length=0.08)
```

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="1st nearest neighbours")
plot(k1, coords, add=TRUE, col="red", length=0.08)
plot(hunan$geometry, border="lightgrey", main="Distance link")
plot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)
```

## Computing adaptive distance weight matrix

```{r}
# Now fix the average number of neighbours
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6

# View as str
str(knn6)
```

Now plot this graph as connections

```{r}
plot(hunan$geometry, border="lightgrey")
plot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

# Part 5 : Weights based on IDW

Now we can try the inverse distance weighting, which tries to estimate values of a point based on the its neighbours. This assumes that neighbours closer to this point are more similar to the point in question than the further points

```{r}
dist <- nbdists(wm_q, coords, longlat = TRUE)
ids <- lapply(dist, function(x) 1/(x))
ids
```

# Part 6 : Row-standardised Weights Matrix

```{r}
# Style also can use "B" for binary and "C" for column
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

```{r}
rswm_q$weights[1]

rswm_ids <- nb2listw(wm_q, glist=ids, style="B", zero.policy=TRUE)
rswm_ids

rswm_ids$weights[1]

summary(unlist(rswm_ids$weights))
```

# Part 7 : Application of Spatial Weight Matrix

## Spatial lag with row-standardized weights

Lag represents the size of the search space. Think of it as the kernel size in the convolutional neural network, where the base case is k=1. Each order increases the kernel size by 1.

Calculate average GCPPC value

```{r}
GDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)
GDPPC.lag
```

```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```

**Question** : From what I see, since the you append the weighted average of the GDP to each region by row, you are essentially spreading out the GDP of each neighbouring county so that the spread of GDP per county is more even and regions of high GDPPC can be better represented, since there is an assumption that if a neighbouring region's GDP will affect that particular region's GDP

Add this new column to the sf for plotting

```{r}
lag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))
lag.res <- as.data.frame(lag.list)
colnames(lag.res) <- c("NAME_3", "lag GDPPC")
hunan <- left_join(hunan,lag.res)
```

```{r}
head(hunan)
```

Plot the graphs

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_gdppc <- qtm(hunan, "lag GDPPC")
tmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)
```

## Spatial lag as a sum of neighboring values

Apply binary weights, assign each weight and 1, then reassign

```{r}
b_weights <- lapply(wm_q, function(x) 0*x + 1)
b_weights2 <- nb2listw(wm_q, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

# Compute the lag sum

```{r}
lag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
lag.res <- as.data.frame(lag_sum)
colnames(lag.res) <- c("NAME_3", "lag_sum GDPPC")
```

Add to the Original sf

```{r}
hunan <- left_join(hunan, lag.res)
```

Plot the graph

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_sum_gdppc <- qtm(hunan, "lag_sum GDPPC")
tmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)
```

## Spatial window average

Use diagonals as well? Doesnt the queen formation already solve this?

```{r}
wm_qs <- include.self(wm_q)
```

```{r}
# Do the same as before
wm_qs[[1]]
wm_qs <- nb2listw(wm_qs)
wm_qs

lag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))

lag_w_avg_gpdpc <- lag.listw(wm_qs, 
                             hunan$GDPPC)
lag_w_avg_gpdpc

# Add to the hunan df
lag_wm_qs.res <- as.data.frame(lag.list.wm_qs)
colnames(lag_wm_qs.res) <- c("NAME_3", "lag_window_avg GDPPC")

hunan <- left_join(hunan, lag_wm_qs.res)
```

Compare the lags

```{r}
hunan %>%
  select("County", 
         "lag GDPPC", 
         "lag_window_avg GDPPC") %>%
  kable()
```

Plot the graph

```{r}
w_avg_gdppc <- qtm(hunan, "lag_window_avg GDPPC")
tmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)
```

## Spatial window sum

Same as before, but sum up all the neighbours instead of average

```{r}
wm_qs <- include.self(wm_q)
wm_qs

b_weights <- lapply(wm_qs, function(x) 0*x + 1)
b_weights[1]

b_weights2 <- nb2listw(wm_qs, 
                       glist = b_weights, 
                       style = "B")
b_weights2

w_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
w_sum_gdppc

w_sum_gdppc.res <- as.data.frame(w_sum_gdppc)
colnames(w_sum_gdppc.res) <- c("NAME_3", "w_sum GDPPC")

hunan <- left_join(hunan, w_sum_gdppc.res)

# Compare
hunan %>%
  select("County", "lag_sum GDPPC", "w_sum GDPPC") %>%
  kable()

# Plot
w_sum_gdppc <- qtm(hunan, "w_sum GDPPC")
tmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)
```
